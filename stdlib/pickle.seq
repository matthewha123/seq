from core.file import _gz_errcheck

def pickle[T](x: T, jar: Jar):
    x.__pickle__(jar)

def unpickle[T](jar: Jar):
    return T.__unpickle__(jar)

def dump[T](x: T, f: gzFile):
    x.__pickle__(f.fp)

def load[T](f: gzFile):
    return T.__unpickle__(f.fp)

def _write_raw(jar: Jar, p: cobj, n: int):
    LIMIT = 0x7fffffff
    while n > 0:
        b = n if n < LIMIT else LIMIT
        status = int(_C.gzwrite(jar, p, u32(b)))
        if status != b:
            _gz_errcheck(jar)
            raise IOError("pickle error: gzwrite returned " + str(status))
        p += b
        n -= b

def _read_raw(jar: Jar, p: cobj, n: int):
    LIMIT = 0x7fffffff
    while n > 0:
        b = n if n < LIMIT else LIMIT
        status = int(_C.gzread(jar, p, u32(b)))
        if status != b:
            _gz_errcheck(jar)
            raise IOError("pickle error: gzread returned " + str(status))
        p += b
        n -= b

def _write[T](jar: Jar, x: T):
    _write_raw(jar, cobj(__ptr__(x)), _gc.sizeof[T]())

def _read[T](jar: Jar):
    x = T()
    _read_raw(jar, cobj(__ptr__(x)), _gc.sizeof[T]())
    return x

# Extend core types to allow pickling

extend int:
    def __pickle__(self: int, jar: Jar):
        _write(jar, self)

    def __unpickle__(jar: Jar):
        return _read[int](jar)

extend float:
    def __pickle__(self: float, jar: Jar):
        _write(jar, self)

    def __unpickle__(jar: Jar):
        return _read[float](jar)

extend bool:
    def __pickle__(self: bool, jar: Jar):
        _write(jar, self)

    def __unpickle__(jar: Jar):
        return _read[bool](jar)

extend byte:
    def __pickle__(self: byte, jar: Jar):
        _write(jar, self)

    def __unpickle__(jar: Jar):
        return _read[byte](jar)

extend str:
    def __pickle__(self: str, jar: Jar):
        _write(jar, self.len)
        _write_raw(jar, self.ptr, self.len)

    def __unpickle__(jar: Jar):
        n = _read[int](jar)
        p = ptr[byte](n)
        _read_raw(jar, p, n)
        return str(p, n)

extend seq:
    def __pickle__(self: seq, jar: Jar):
        _write(jar, self.len)
        _write_raw(jar, self.ptr, abs(self.len))

    def __unpickle__(jar: Jar):
        n = _read[int](jar)
        m = abs(n)
        p = ptr[byte](m)
        _read_raw(jar, p, m)
        return seq(p, n)

extend list[T]:
    def __pickle__(self: list[T], jar: Jar):
        n = len(self)
        pickle(n, jar)
        if _gc.atomic[T]():
            _write_raw(jar, ptr[byte](self.arr.ptr), n * _gc.sizeof[T]())
        else:
            for i in range(n):
                pickle(self.arr[i], jar)

    def __unpickle__(jar: Jar):
        n = unpickle[int](jar)
        arr = array[T](n)
        if _gc.atomic[T]():
            _read_raw(jar, ptr[byte](arr.ptr), n * _gc.sizeof[T]())
        else:
            for i in range(n):
                arr[i] = unpickle[T](jar)
        return list[T](arr, n)

extend dict[K, V]:
    def __pickle__(self: dict[K,V], jar: Jar):
        import core.collections.khash as khash
        if _gc.atomic[K]() and _gc.atomic[V]():
            pickle(self._n_buckets, jar)
            pickle(self._size, jar)
            pickle(self._n_occupied, jar)
            pickle(self._upper_bound, jar)
            fsize = khash.__ac_fsize(self._n_buckets) if self._n_buckets > 0 else 0
            _write_raw(jar, ptr[byte](self._flags), fsize * _gc.sizeof[u32]())
            _write_raw(jar, ptr[byte](self._keys), self._n_buckets * _gc.sizeof[K]())
            _write_raw(jar, ptr[byte](self._vals), self._n_buckets * _gc.sizeof[V]())
        else:
            pickle(self._n_buckets, jar)
            size = len(self)
            pickle(size, jar)

            for k,v in self.items():
                pickle(k, jar)
                pickle(v, jar)

    def __unpickle__(jar: Jar):
        import core.collections.khash as khash
        d = dict[K,V]()
        if _gc.atomic[K]() and _gc.atomic[V]():
            n_buckets = unpickle[int](jar)
            size = unpickle[int](jar)
            n_occupied = unpickle[int](jar)
            upper_bound = unpickle[int](jar)
            fsize = khash.__ac_fsize(n_buckets) if n_buckets > 0 else 0
            flags = ptr[u32](fsize)
            keys = ptr[K](n_buckets)
            vals = ptr[V](n_buckets)
            _read_raw(jar, ptr[byte](flags), fsize * _gc.sizeof[u32]())
            _read_raw(jar, ptr[byte](keys), n_buckets * _gc.sizeof[K]())
            _read_raw(jar, ptr[byte](vals), n_buckets * _gc.sizeof[V]())

            d._n_buckets = n_buckets
            d._size = size
            d._n_occupied = n_occupied
            d._upper_bound = upper_bound
            d._flags = flags
            d._keys = keys
            d._vals = vals
        else:
            n_buckets = unpickle[int](jar)
            size = unpickle[int](jar)
            d.resize(n_buckets)
            i = 0
            while i < size:
                k = unpickle[K](jar)
                v = unpickle[V](jar)
                d[k] = v
                i += 1
        return d

extend set[K]:
    def __pickle__(self: set[K], jar: Jar):
        import core.collections.khash as khash
        if _gc.atomic[K]():
            pickle(self._n_buckets, jar)
            pickle(self._size, jar)
            pickle(self._n_occupied, jar)
            pickle(self._upper_bound, jar)
            fsize = khash.__ac_fsize(self._n_buckets) if self._n_buckets > 0 else 0
            _write_raw(jar, ptr[byte](self._flags), fsize * _gc.sizeof[u32]())
            _write_raw(jar, ptr[byte](self._keys), self._n_buckets * _gc.sizeof[K]())
        else:
            pickle(self._n_buckets, jar)
            size = len(self)
            pickle(size, jar)

            for k in self:
                pickle(k, jar)

    def __unpickle__(jar: Jar):
        import core.collections.khash as khash
        s = set[K]()
        if _gc.atomic[K]():
            n_buckets = unpickle[int](jar)
            size = unpickle[int](jar)
            n_occupied = unpickle[int](jar)
            upper_bound = unpickle[int](jar)
            fsize = khash.__ac_fsize(n_buckets) if n_buckets > 0 else 0
            flags = ptr[u32](fsize)
            keys = ptr[K](n_buckets)
            _read_raw(jar, ptr[byte](flags), fsize * _gc.sizeof[u32]())
            _read_raw(jar, ptr[byte](keys), n_buckets * _gc.sizeof[K]())

            s._n_buckets = n_buckets
            s._size = size
            s._n_occupied = n_occupied
            s._upper_bound = upper_bound
            s._flags = flags
            s._keys = keys
        else:
            n_buckets = unpickle[int](jar)
            size = unpickle[int](jar)
            s.resize(n_buckets)
            i = 0
            while i < size:
                k = unpickle[K](jar)
                s.add(k)
                i += 1
        return s
